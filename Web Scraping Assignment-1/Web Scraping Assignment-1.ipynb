{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                           web scraping assignment-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6e1ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=0e6ba171f77940641a2e995c5fbbcb059eaf2d9c8464c4598076ff498a8d45c2\n",
      "  Stored in directory: c:\\users\\jkart\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf54013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jkart\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jkart\\anaconda3\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d30af6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6a84bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "156b41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header : Main Page\n",
      "Header : Welcome toWikipedia\n",
      "Header : From today's featured article\n",
      "Header : Did you knowÂ ...\n",
      "Header : In the news\n",
      "Header : On this day\n",
      "Header : Today's featured picture\n",
      "Header : Other areas of Wikipedia\n",
      "Header : Wikipedia's sister projects\n",
      "Header : Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        headers = []\n",
    "\n",
    "        for header_level in range(1, 7): \n",
    "            header_tags = soup.find_all(f'h{header_level}')\n",
    "            for header_tag in header_tags:\n",
    "                headers.append({\n",
    "                    'level': header_level,\n",
    "                    'text': header_tag.get_text(strip=True)\n",
    "                })\n",
    "\n",
    "        return headers\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    website_url = \"https://en.wikipedia.org/wiki/Main_Page\"  \n",
    "    extracted_headers = data(website_url)\n",
    "\n",
    "    for header in extracted_headers:\n",
    "        print(f\"Header : {header['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3a92d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "391602ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n",
      "  Rank            Team Matches Points Rating\n",
      "0    1    AustraliaAUS      23  2,714    118\n",
      "1    2     PakistanPAK      20  2,316    116\n",
      "2    3        IndiaIND      36  4,081    113\n",
      "3    4   New ZealandNZ      27  2,806    104\n",
      "4    5      EnglandENG      24  2,426    101\n",
      "5    6  South AfricaSA      19  1,910    101\n",
      "6    7   BangladeshBAN      28  2,661     95\n",
      "7    8  AfghanistanAFG      16  1,404     88\n",
      "8    9     Sri LankaSL      32  2,794     87\n",
      "9   10   West IndiesWI      38  2,582     68\n"
     ]
    }
   ],
   "source": [
    "def data1(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    teams = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        team = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Team': cols[1].get_text(strip=True),\n",
    "            'Matches': cols[2].get_text(strip=True),\n",
    "            'Points': cols[3].get_text(strip=True),\n",
    "            'Rating': cols[4].get_text(strip=True)\n",
    "        }\n",
    "        teams.append(team)\n",
    "\n",
    "    return teams\n",
    "\n",
    "def scrape_odi_players(url, category):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    players = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        player = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Player': cols[1].get_text(strip=True),\n",
    "            'Team': cols[2].get_text(strip=True),\n",
    "            'Rating': cols[3].get_text(strip=True)\n",
    "        }\n",
    "        players.append(player)\n",
    "\n",
    "    return players\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "    \n",
    "    # top 10 ODI teams\n",
    "    teams_url = base_url\n",
    "    odi_teams = data1 (teams_url)\n",
    "    odi_teams_df = pd.DataFrame(odi_teams)\n",
    "    \n",
    "    print(\"Top 10 ODI Teams:\")\n",
    "    print(odi_teams_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11742450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dafa9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen:\n",
      "                                                Rank                 Player  \\\n",
      "0                                               1(0)             Babar Azam   \n",
      "1                                               2(0)  Rassie van der Dussen   \n",
      "2                                               3(0)           Fakhar Zaman   \n",
      "3                                               4(0)            Imam-ul-Haq   \n",
      "4  5(2)This player has moved up in the rankings s...           Shubman Gill   \n",
      "5  6(1)This player has moved down in the rankings...           Harry Tector   \n",
      "6  =(1)This player has moved down in the rankings...           David Warner   \n",
      "7                                               8(0)        Quinton de Kock   \n",
      "8                                               9(0)            Virat Kohli   \n",
      "9                                              10(0)            Steve Smith   \n",
      "\n",
      "  Team Rating  \n",
      "0  PAK    886  \n",
      "1   SA    777  \n",
      "2  PAK    755  \n",
      "3  PAK    745  \n",
      "4  IND    743  \n",
      "5  IRE    726  \n",
      "6  AUS    726  \n",
      "7   SA    718  \n",
      "8  IND    705  \n",
      "9  AUS    702  \n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    batsmen = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]: \n",
    "        cols = row.find_all('td')\n",
    "        batsman = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Player': cols[1].get_text(strip=True),\n",
    "            'Team': cols[2].get_text(strip=True),\n",
    "            'Rating': cols[3].get_text(strip=True)\n",
    "        }\n",
    "        batsmen.append(batsman)\n",
    "\n",
    "    return batsmen\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "    \n",
    "    # top 10 ODI Batsmen\n",
    "    odi_batsmen = data(base_url)\n",
    "    odi_batsmen_df = pd.DataFrame(odi_batsmen)\n",
    "    \n",
    "    print(\"Top 10 ODI Batsmen:\")\n",
    "    print(odi_batsmen_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97782b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad90112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Bowlers:\n",
      "                                                Rank            Player Team  \\\n",
      "0                                               1(0)    Josh Hazlewood  AUS   \n",
      "1                                               2(0)    Mitchell Starc  AUS   \n",
      "2                                               3(0)       Rashid Khan  AFG   \n",
      "3                                               4(0)    Mohammed Siraj  IND   \n",
      "4                                               5(0)        Matt Henry   NZ   \n",
      "5                                               6(0)  Mujeeb Ur Rahman  AFG   \n",
      "6                                               7(0)       Trent Boult   NZ   \n",
      "7                                               8(0)        Adam Zampa  AUS   \n",
      "8                                               9(0)    Shaheen Afridi  PAK   \n",
      "9  10(4)This player has moved up in the rankings ...     Kuldeep Yadav  IND   \n",
      "\n",
      "  Rating  \n",
      "0    705  \n",
      "1    686  \n",
      "2    682  \n",
      "3    670  \n",
      "4    667  \n",
      "5    661  \n",
      "6    660  \n",
      "7    652  \n",
      "8    630  \n",
      "9    622  \n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    bowlers = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        bowler = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Player': cols[1].get_text(strip=True),\n",
    "            'Team': cols[2].get_text(strip=True),\n",
    "            'Rating': cols[3].get_text(strip=True)\n",
    "        }\n",
    "        bowlers.append(bowler)\n",
    "\n",
    "    return bowlers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "    \n",
    "    # top 10 ODI Bowlers\n",
    "    odi_bowlers = data(base_url)\n",
    "    odi_bowlers_df = pd.DataFrame(odi_bowlers)\n",
    "    \n",
    "    print(\"Top 10 ODI Bowlers:\")\n",
    "    print(odi_bowlers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e39a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fa8f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Women's Teams:\n",
      "  Rank            Team Matches Points Rating\n",
      "0    1    AustraliaAUS      26  4,290    165\n",
      "1    2      EnglandENG      31  3,875    125\n",
      "2    3  South AfricaSA      26  3,098    119\n",
      "3    4        IndiaIND      30  3,039    101\n",
      "4    5   New ZealandNZ      28  2,688     96\n",
      "5    6   West IndiesWI      29  2,743     95\n",
      "6    7   BangladeshBAN      17  1,284     76\n",
      "7    8     Sri LankaSL      12    820     68\n",
      "8    9     ThailandTHA      13    883     68\n",
      "9   10     PakistanPAK      27  1,678     62\n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    teams = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        team = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Team': cols[1].get_text(strip=True),\n",
    "            'Matches': cols[2].get_text(strip=True),\n",
    "            'Points': cols[3].get_text(strip=True),\n",
    "            'Rating': cols[4].get_text(strip=True)\n",
    "        }\n",
    "        teams.append(team)\n",
    "\n",
    "    return teams\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "    \n",
    "    # top 10 ODI Women's teams\n",
    "    odi_womens_teams = data(base_url)\n",
    "    odi_womens_teams_df = pd.DataFrame(odi_womens_teams)\n",
    "    \n",
    "    print(\"Top 10 ODI Women's Teams:\")\n",
    "    print(odi_womens_teams_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "589c9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e39b9440",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Women's Batting Players:\n",
      "                                                Rank                Player  \\\n",
      "0                                               1(0)  Natalie Sciver-Brunt   \n",
      "1                                               2(0)   Chamari Athapaththu   \n",
      "2                                               3(0)           Beth Mooney   \n",
      "3                                               4(0)       Laura Wolvaardt   \n",
      "4  5(1)This player has moved up in the rankings s...       Smriti Mandhana   \n",
      "5  6(1)This player has moved down in the rankings...          Alyssa Healy   \n",
      "6                                               7(0)      Harmanpreet Kaur   \n",
      "7                                               8(0)          Ellyse Perry   \n",
      "8                                               9(0)           Meg Lanning   \n",
      "9                                              10(0)       Stafanie Taylor   \n",
      "\n",
      "  Team Rating  \n",
      "0  ENG    803  \n",
      "1   SL    758  \n",
      "2  AUS    751  \n",
      "3   SA    732  \n",
      "4  IND    708  \n",
      "5  AUS    702  \n",
      "6  IND    694  \n",
      "7  AUS    686  \n",
      "8  AUS    682  \n",
      "9   WI    618  \n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    players = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        player = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Player': cols[1].get_text(strip=True),\n",
    "            'Team': cols[2].get_text(strip=True),\n",
    "            'Rating': cols[3].get_text(strip=True)\n",
    "        }\n",
    "        players.append(player)\n",
    "\n",
    "    return players\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "    \n",
    "    # top 10 ODI Women's batting players\n",
    "    odi_womens_batting_players = data(base_url)\n",
    "    odi_womens_batting_players_df = pd.DataFrame(odi_womens_batting_players)\n",
    "    \n",
    "    print(\"Top 10 ODI Women's Batting Players:\")\n",
    "    print(odi_womens_batting_players_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51905812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8ca19c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Women's All-rounders:\n",
      "    Rank                Player Team Rating\n",
      "0   1(0)  Natalie Sciver-Brunt  ENG    421\n",
      "1   2(0)      Ashleigh Gardner  AUS    389\n",
      "2   3(0)       Hayley Matthews   WI    382\n",
      "3   4(0)        Marizanne Kapp   SA    349\n",
      "4   5(0)          Ellyse Perry  AUS    329\n",
      "5   6(0)           Amelia Kerr   NZ    328\n",
      "6   7(0)         Deepti Sharma  IND    312\n",
      "7   8(0)         Jess Jonassen  AUS    241\n",
      "8   9(0)         Sophie Devine   NZ    233\n",
      "9  10(0)              Nida Dar  PAK    232\n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    allrounders = []\n",
    "    table = soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:11]:  \n",
    "        cols = row.find_all('td')\n",
    "        allrounder = {\n",
    "            'Rank': cols[0].get_text(strip=True),\n",
    "            'Player': cols[1].get_text(strip=True),\n",
    "            'Team': cols[2].get_text(strip=True),\n",
    "            'Rating': cols[3].get_text(strip=True)\n",
    "        }\n",
    "        allrounders.append(allrounder)\n",
    "\n",
    "    return allrounders\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "    \n",
    "    # top 10 ODI Women's all-rounders\n",
    "    odi_womens_allrounders = data(base_url)\n",
    "    odi_womens_allrounders_df = pd.DataFrame(odi_womens_allrounders)\n",
    "    \n",
    "    print(\"Top 10 ODI Women's All-rounders:\")\n",
    "    print(odi_womens_allrounders_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecc67f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61ce8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8c3eda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5aa225f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c9cbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headline\n",
    "\n",
    "news_headline = []\n",
    "\n",
    "for i in soup.find_all(\"a\", class_='LatestNews-headline'):\n",
    "    news_headline.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abbb230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n",
    "news_time = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"LatestNews-wrapper\"):\n",
    "    news_time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a7c1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link\n",
    "news_link = []\n",
    "\n",
    "for i in soup.find_all(\"a\", class_='LatestNews-headline'):\n",
    "    news_link.append(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0932618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ex-software engineer brings in $129,000 a year...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/ex-software-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to start investing for the long haul for t...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/how-to-start-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'The coolest summer job': Meet Wisconsin's tee...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/the-coolest-su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With Lionel Messi playing soccer in the U.S., ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/lionel-messi-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Young Bill Gates thought school wasn't 'intere...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/bill-gates-tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why startups are investing millions to make dr...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/startups-inves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lawmakers weigh tax rule 'backslide' for Venmo...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/some-lawmakers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Here's the trade on Nvidia ahead of earnings, ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/heres-the-trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitcoin had a big drop late last week. Here's ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/20/bitcoin-had-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Why 'career choices' is the No. 1 conflict amo...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/why-career-cho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cruise will reduce robotaxi fleet by 50% in Sa...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/cruise-will-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Can American-made weapons like F-16s turn the ...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/can-expensive-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Harvard gut doctor avoids these 4 foods that c...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/harvard-gut-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The clash of sustainability and AI is creating...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/the-clash-of-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>On tap next week: 2 housing reports and 2 Inve...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/on-tap-next-we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Top 10 best European cities for retirement</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/best-countries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Google's plan to purge inactive accounts isn't...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/google-faces-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The No. 1 best state to retire in the U.S.âit'...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/best-us-states...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mark Cuban passed on an Uber investment that c...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/mark-cuban-pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Believing these 5 Social Security myths may re...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/social-securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Here's why Aldi is looking to the Southern U.S...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/aldi-winn-dixi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here's how the Huy Fong Foods sriracha shortag...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/how-did-the-hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This ETF is soaring in August as market swoon ...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/this-etf-is-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Morgan Stanley is among the most oversold in t...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/morgan-stanley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Buy these stocks with upside as market fears i...</td>\n",
       "      <td>August 19, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/19/goldman-picks-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Palo Alto shares rise on earnings beat, after ...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/palo-alto-netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wall Street awaits hotly anticipated Nvidia ea...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/wall-street-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>WeWork plunges another 11% after announcing re...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/wework-plunges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The iPhone 15 could get one of the biggest upg...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/iphone-15-usb-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Coral bleaching event in Florida is 'just the ...</td>\n",
       "      <td>August 18, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/08/18/noaa-florida-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline             Time  \\\n",
       "1   Ex-software engineer brings in $129,000 a year...       1 Hour Ago   \n",
       "2   How to start investing for the long haul for t...       1 Hour Ago   \n",
       "3   'The coolest summer job': Meet Wisconsin's tee...       1 Hour Ago   \n",
       "4   With Lionel Messi playing soccer in the U.S., ...      2 Hours Ago   \n",
       "5   Young Bill Gates thought school wasn't 'intere...      2 Hours Ago   \n",
       "6   Why startups are investing millions to make dr...      2 Hours Ago   \n",
       "7   Lawmakers weigh tax rule 'backslide' for Venmo...      3 Hours Ago   \n",
       "8   Here's the trade on Nvidia ahead of earnings, ...      3 Hours Ago   \n",
       "9   Bitcoin had a big drop late last week. Here's ...      3 Hours Ago   \n",
       "10  Why 'career choices' is the No. 1 conflict amo...     21 Hours Ago   \n",
       "11  Cruise will reduce robotaxi fleet by 50% in Sa...     23 Hours Ago   \n",
       "12  Can American-made weapons like F-16s turn the ...     23 Hours Ago   \n",
       "13  Harvard gut doctor avoids these 4 foods that c...  August 19, 2023   \n",
       "14  The clash of sustainability and AI is creating...  August 19, 2023   \n",
       "15  On tap next week: 2 housing reports and 2 Inve...  August 19, 2023   \n",
       "16        Top 10 best European cities for retirement   August 19, 2023   \n",
       "17  Google's plan to purge inactive accounts isn't...  August 19, 2023   \n",
       "18  The No. 1 best state to retire in the U.S.âit'...  August 19, 2023   \n",
       "19  Mark Cuban passed on an Uber investment that c...  August 19, 2023   \n",
       "20  Believing these 5 Social Security myths may re...  August 19, 2023   \n",
       "21  Here's why Aldi is looking to the Southern U.S...  August 19, 2023   \n",
       "22  Here's how the Huy Fong Foods sriracha shortag...  August 19, 2023   \n",
       "23  This ETF is soaring in August as market swoon ...  August 19, 2023   \n",
       "24  Morgan Stanley is among the most oversold in t...  August 19, 2023   \n",
       "25  Buy these stocks with upside as market fears i...  August 19, 2023   \n",
       "26  Palo Alto shares rise on earnings beat, after ...  August 18, 2023   \n",
       "27  Wall Street awaits hotly anticipated Nvidia ea...  August 18, 2023   \n",
       "28  WeWork plunges another 11% after announcing re...  August 18, 2023   \n",
       "29  The iPhone 15 could get one of the biggest upg...  August 18, 2023   \n",
       "30  Coral bleaching event in Florida is 'just the ...  August 18, 2023   \n",
       "\n",
       "                                            News link  \n",
       "1   https://www.cnbc.com/2023/08/20/ex-software-en...  \n",
       "2   https://www.cnbc.com/2023/08/20/how-to-start-i...  \n",
       "3   https://www.cnbc.com/2023/08/20/the-coolest-su...  \n",
       "4   https://www.cnbc.com/2023/08/20/lionel-messi-j...  \n",
       "5   https://www.cnbc.com/2023/08/20/bill-gates-tho...  \n",
       "6   https://www.cnbc.com/2023/08/20/startups-inves...  \n",
       "7   https://www.cnbc.com/2023/08/20/some-lawmakers...  \n",
       "8   https://www.cnbc.com/2023/08/20/heres-the-trad...  \n",
       "9   https://www.cnbc.com/2023/08/20/bitcoin-had-a-...  \n",
       "10  https://www.cnbc.com/2023/08/19/why-career-cho...  \n",
       "11  https://www.cnbc.com/2023/08/19/cruise-will-re...  \n",
       "12  https://www.cnbc.com/2023/08/19/can-expensive-...  \n",
       "13  https://www.cnbc.com/2023/08/19/harvard-gut-do...  \n",
       "14  https://www.cnbc.com/2023/08/19/the-clash-of-s...  \n",
       "15  https://www.cnbc.com/2023/08/19/on-tap-next-we...  \n",
       "16  https://www.cnbc.com/2023/08/19/best-countries...  \n",
       "17  https://www.cnbc.com/2023/08/19/google-faces-c...  \n",
       "18  https://www.cnbc.com/2023/08/19/best-us-states...  \n",
       "19  https://www.cnbc.com/2023/08/19/mark-cuban-pas...  \n",
       "20  https://www.cnbc.com/2023/08/19/social-securit...  \n",
       "21  https://www.cnbc.com/2023/08/19/aldi-winn-dixi...  \n",
       "22  https://www.cnbc.com/2023/08/19/how-did-the-hu...  \n",
       "23  https://www.cnbc.com/2023/08/19/this-etf-is-so...  \n",
       "24  https://www.cnbc.com/2023/08/19/morgan-stanley...  \n",
       "25  https://www.cnbc.com/2023/08/19/goldman-picks-...  \n",
       "26  https://www.cnbc.com/2023/08/18/palo-alto-netw...  \n",
       "27  https://www.cnbc.com/2023/08/18/wall-street-pr...  \n",
       "28  https://www.cnbc.com/2023/08/18/wework-plunges...  \n",
       "29  https://www.cnbc.com/2023/08/18/iphone-15-usb-...  \n",
       "30  https://www.cnbc.com/2023/08/18/noaa-florida-c...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "\n",
    "df = pd.DataFrame({'Headline': news_headline, 'Time': news_time, 'News link': news_link})\n",
    "\n",
    "df.index=df.index+1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69f1c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "247b8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Article Details:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    articles = []\n",
    "    cards = soup.find_all('div', class_='pod-listing-pod-image')\n",
    "    for card in cards:\n",
    "        title = card.find('h3', class_='pod-listing-header').text.strip()\n",
    "        authors = card.find('p', class_='pod-listing-authors').text.strip()\n",
    "        published_date = card.find('p', class_='pod-listing-published').text.strip()\n",
    "        paper_url = card.find('a', class_='pod-listing-title')['href']\n",
    "\n",
    "        articles.append({\n",
    "            'Paper Title': title,\n",
    "            'Authors': authors,\n",
    "            'Published Date': published_date,\n",
    "            'Paper URL': paper_url\n",
    "        })\n",
    "\n",
    "    return articles\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "    \n",
    "    # article details\n",
    "    article_data = data(base_url)\n",
    "    article_df = pd.DataFrame(article_data)\n",
    "    \n",
    "    print(\"Scraped Article Details:\")\n",
    "    print(article_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "821acdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "795820e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Restaurant Details:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    restaurants = []\n",
    "    cards = soup.find_all('div', class_='restaurant-card-container')\n",
    "    for card in cards:\n",
    "        name = card.find('h2', class_='restaurant-name').text.strip()\n",
    "        cuisine = card.find('p', class_='restaurant-cuisine').text.strip()\n",
    "        location = card.find('p', class_='restaurant-location').text.strip()\n",
    "        ratings = card.find('span', class_='restaurant-rating').text.strip()\n",
    "        img_url = card.find('img')['data-src']\n",
    "\n",
    "        restaurants.append({\n",
    "            'Restaurant Name': name,\n",
    "            'Cuisine': cuisine,\n",
    "            'Location': location,\n",
    "            'Ratings': ratings,\n",
    "            'Image URL': img_url\n",
    "        })\n",
    "\n",
    "    return restaurants\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
    "    \n",
    "    # restaurant details\n",
    "    restaurant_data = data(base_url)\n",
    "    restaurant_df = pd.DataFrame(restaurant_data)\n",
    "    \n",
    "    print(\"Scraped Restaurant Details:\")\n",
    "    print(restaurant_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f12db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
